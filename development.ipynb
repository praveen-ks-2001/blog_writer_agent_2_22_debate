{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e3f7a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langgraph==1.0.9 langchain==1.2.10 openai python-dotenv langchain-openai langchain-core langchain-anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a650e0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd597009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import TypedDict, Optional, List\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from langgraph.types import interrupt\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac13bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Debate Output Schemas\n",
    "# -----------------------\n",
    "\n",
    "class DebateOption(BaseModel):\n",
    "    title: str\n",
    "    description: str\n",
    "\n",
    "\n",
    "class DebateOptionsOutput(BaseModel):\n",
    "    options: List[DebateOption]\n",
    "\n",
    "\n",
    "class DebateSummary(BaseModel):\n",
    "    side_a_points: List[str]\n",
    "    side_b_points: List[str]\n",
    "    tensions: List[str]\n",
    "\n",
    "# -----------------------\n",
    "# Writer Chat Memory Store\n",
    "# -----------------------\n",
    "writer_store = {}\n",
    "def get_writer_session_history(session_id: str):\n",
    "    if session_id not in writer_store:\n",
    "        writer_store[session_id] = InMemoryChatMessageHistory()\n",
    "    return writer_store[session_id]\n",
    "\n",
    "writer_base_llm = ChatOpenAI(\n",
    "    model=\"gpt-5-2\",\n",
    "    temperature=0.7,\n",
    "    api_key=OPENAI_API_KEY\n",
    ")\n",
    "writer_llm = RunnableWithMessageHistory(\n",
    "    writer_base_llm,\n",
    "    get_writer_session_history,\n",
    "    input_messages_key=\"input\",\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# Blog State Schema\n",
    "# -----------------------\n",
    "\n",
    "class BlogState(BaseModel):\n",
    "    # Raw + cleaned input\n",
    "    brain_dump_raw: Optional[str] = None\n",
    "    brain_dump_cleaned: Optional[str] = None\n",
    "\n",
    "    reconstruct_scene: Optional[str] = None\n",
    "\n",
    "    debate_options: List[DebateOption] = Field(default_factory=list)\n",
    "    selected_debate_option: Optional[str] = None\n",
    "\n",
    "    debate_full: Optional[str] = None\n",
    "    debate_summary: Optional[DebateSummary] = None\n",
    "\n",
    "    story_arc_outline: Optional[str] = None\n",
    "\n",
    "    voice_fingerprint: Optional[str] = None\n",
    "\n",
    "    current_draft: Optional[str] = None\n",
    "    judge_feedback: Optional[str] = None\n",
    "\n",
    "    # Used for user feedback in revision loop\n",
    "    user_input: Optional[str] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc221ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Brain Dump Cleaner\n",
    "def clean_brain_dump(state: BlogState):\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-5-mini\", \n",
    "        temperature=0.7, \n",
    "        api_key=OPENAI_API_KEY\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    [CLEANER PROMPT PLACEHOLDER]\n",
    "\n",
    "    TEXT:\n",
    "    {state.brain_dump_raw}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    state.brain_dump_cleaned = response.content\n",
    "    return state\n",
    "\n",
    "# 2. Memory Reconstruction\n",
    "def reconstruct_memory(state: BlogState):\n",
    "    llm = ChatAnthropic(\n",
    "        model=\"claude-sonnet-4-6\",\n",
    "        temperature=0.7,\n",
    "        api_key=ANTHROPIC_API_KEY\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    [RECONSTRUCTION PROMPT PLACEHOLDER]\n",
    "\n",
    "    TEXT:\n",
    "    {state.brain_dump_cleaned}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    state.reconstruct_scene = response.content\n",
    "    return state\n",
    "\n",
    "# 3. Debate Options\n",
    "def generate_debate_options(state: BlogState):\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-5-mini\",\n",
    "        temperature=0.7,\n",
    "        api_key=OPENAI_API_KEY\n",
    "    )\n",
    "\n",
    "    structured_llm = llm.with_structured_output(DebateOptionsOutput)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    [DEBATE OPTIONS PROMPT PLACEHOLDER]\n",
    "\n",
    "    TEXT:\n",
    "    {state.brain_dump_cleaned}\n",
    "    \"\"\"\n",
    "\n",
    "    result: DebateOptionsOutput = structured_llm.invoke(prompt)\n",
    "\n",
    "    state.debate_options = result.options\n",
    "\n",
    "    return interrupt(state)   \n",
    "\n",
    "\n",
    "# 4. Debate Generator\n",
    "def generate_debate(state: BlogState):\n",
    "    llm = ChatAnthropic(\n",
    "        model=\"claude-sonnet-4-6\",\n",
    "        temperature=0.7,\n",
    "        api_key=ANTHROPIC_API_KEY\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    [DEBATE GENERATION PROMPT PLACEHOLDER]\n",
    "\n",
    "    Selected Topic:\n",
    "    {state.selected_debate_option}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    state.debate_full = response.content\n",
    "\n",
    "    with open(\"debate_full.md\", \"w\") as f:\n",
    "        f.write(state.debate_full)\n",
    "\n",
    "    return state\n",
    "\n",
    "# 5. Debate Distiller\n",
    "def distill_debate(state: BlogState):\n",
    "    llm = ChatOpenAI(\n",
    "        model=\"gpt-5-mini\", \n",
    "        temperature=0.7, \n",
    "        api_key=OPENAI_API_KEY\n",
    "    )\n",
    "\n",
    "    structured_llm = llm.with_structured_output(DebateSummary)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    [DEBATE DISTILLER PROMPT PLACEHOLDER]\n",
    "\n",
    "    TEXT:\n",
    "    {state.debate_full}\n",
    "    \"\"\"\n",
    "\n",
    "    result: DebateSummary = structured_llm.invoke(prompt)\n",
    "\n",
    "    state.debate_summary = result\n",
    "\n",
    "    with open(\"debate_summary.md\", \"w\") as f:\n",
    "        f.write(result.model_dump_json(indent=2))\n",
    "\n",
    "    return state\n",
    "\n",
    "# 6. Story Arc Generator\n",
    "def generate_story_arc(state: BlogState):\n",
    "    llm = ChatAnthropic(\n",
    "        model=\"claude-sonnet-4-6\",\n",
    "        temperature=0.7,\n",
    "        api_key=ANTHROPIC_API_KEY\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    [STORY ARC PROMPT PLACEHOLDER]\n",
    "\n",
    "    Brain Dump:\n",
    "    {state.brain_dump_cleaned}\n",
    "\n",
    "    Scene:\n",
    "    {state.reconstruct_scene}\n",
    "\n",
    "    Debate Summary:\n",
    "    {state.debate_summary.model_dump()}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    state.story_arc_outline = response.content\n",
    "    return interrupt(state)\n",
    "\n",
    "# 7. Draft Writer\n",
    "def write_draft(state: BlogState, config):\n",
    "    prompt = f\"\"\"\n",
    "    [WRITER PROMPT PLACEHOLDER]\n",
    "\n",
    "    VOICE:\n",
    "    {state.voice_fingerprint}\n",
    "\n",
    "    SCENE:\n",
    "    {state.reconstruct_scene}\n",
    "\n",
    "    STORY ARC:\n",
    "    {state.story_arc_outline}\n",
    "\n",
    "    DEBATE SUMMARY:\n",
    "    {state.debate_summary.model_dump()}\n",
    "    \"\"\"\n",
    "\n",
    "    session_id = config[\"configurable\"][\"thread_id\"]\n",
    "\n",
    "    response = writer_llm.invoke(\n",
    "        {\"input\": prompt},\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "\n",
    "    state.current_draft = response.content\n",
    "    return state\n",
    "\n",
    "# 8. Judge\n",
    "def judge_draft(state: BlogState):\n",
    "    llm = ChatAnthropic(\n",
    "        model=\"claude-sonnet-4-6\",\n",
    "        temperature=0.7,\n",
    "        api_key=ANTHROPIC_API_KEY\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    [JUDGE PROMPT PLACEHOLDER]\n",
    "\n",
    "    VOICE FILE:\n",
    "    {state.voice_fingerprint}\n",
    "\n",
    "    BLOG:\n",
    "    {state.current_draft}\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    state.judge_feedback = response.content\n",
    "    return interrupt(state)\n",
    "\n",
    "# 9. Revision Node\n",
    "def revise_draft(state: BlogState, config):\n",
    "    prompt = f\"\"\"\n",
    "    [REVISION PROMPT PLACEHOLDER]\n",
    "\n",
    "    VOICE:\n",
    "    {state.voice_fingerprint}\n",
    "\n",
    "    USER FEEDBACK:\n",
    "    {state.user_input}\n",
    "    \"\"\"\n",
    "\n",
    "    session_id = config[\"configurable\"][\"thread_id\"]\n",
    "\n",
    "    response = writer_llm.invoke(\n",
    "        {\"input\": prompt},\n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "\n",
    "    state.current_draft = response.content\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa7636e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x1b7a8d35be0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workflow = StateGraph(BlogState)\n",
    "\n",
    "workflow.add_node(\"clean\", clean_brain_dump)\n",
    "workflow.add_node(\"reconstruct\", reconstruct_memory)\n",
    "workflow.add_node(\"debate_options\", generate_debate_options)\n",
    "workflow.add_node(\"debate\", generate_debate)\n",
    "workflow.add_node(\"distill\", distill_debate)\n",
    "workflow.add_node(\"story_arc\", generate_story_arc)\n",
    "workflow.add_node(\"write\", write_draft)\n",
    "workflow.add_node(\"judge\", judge_draft)\n",
    "workflow.add_node(\"revise\", revise_draft)\n",
    "\n",
    "## Add connections\n",
    "workflow.set_entry_point(\"clean\")\n",
    "\n",
    "workflow.add_edge(\"clean\", \"reconstruct\")\n",
    "workflow.add_edge(\"reconstruct\", \"debate_options\")\n",
    "workflow.add_edge(\"debate_options\", \"debate\")\n",
    "workflow.add_edge(\"debate\", \"distill\")\n",
    "workflow.add_edge(\"distill\", \"story_arc\")\n",
    "workflow.add_edge(\"story_arc\", \"write\")\n",
    "workflow.add_edge(\"write\", \"judge\")\n",
    "\n",
    "def revision_router(state: BlogState):\n",
    "    if state.user_input == \"approve\":\n",
    "        state.user_input = None\n",
    "        return END\n",
    "    return \"revise\"\n",
    "\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"judge\",\n",
    "    revision_router,\n",
    "    {\n",
    "        \"revise\": \"revise\",\n",
    "        END: END,\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"revise\", \"judge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d23c602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile withmemory\n",
    "checkpointer = MemorySaver()\n",
    "app = workflow.compile(checkpointer=checkpointer)\n",
    "app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d562dd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------\n",
    "# Load input files\n",
    "# -----------------------\n",
    "\n",
    "with open(\"brain_dump.md\", \"r\", encoding=\"utf-8\") as f:\n",
    "    brain_dump_text = f.read()\n",
    "\n",
    "with open(\"voice.md\", \"r\", encoding=\"utf-8\") as f:\n",
    "    voice_text = f.read()\n",
    "\n",
    "# -----------------------\n",
    "# Create Initial State\n",
    "# -----------------------\n",
    "initial_state = BlogState(\n",
    "    brain_dump_raw=brain_dump_text,\n",
    "    voice_fingerprint=voice_text\n",
    ")\n",
    "\n",
    "config = {\"configurable\": {\"thread_id\": \"blog-thread-1\"}}\n",
    "result = app.invoke(initial_state, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc4ff95",
   "metadata": {},
   "source": [
    "### After selecting debate options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617c5c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "state.selected_debate_option = \"Logging is not debugging\"\n",
    "# state.selected_debate_option = state.debate_options[1].title\n",
    "result = app.invoke(state, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d21baf",
   "metadata": {},
   "source": [
    "### After modifying story arc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c78744",
   "metadata": {},
   "outputs": [],
   "source": [
    "state.story_arc_outline = \"updated arc\"\n",
    "# state.user_input = \"approve\"\n",
    "app.invoke(state, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b890bc7",
   "metadata": {},
   "source": [
    "### Modify draft\n",
    "check the current draft and the feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf51adeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "state.user_input = \"Make second paragraph sharper\"\n",
    "# state.user_input = \"approve\"  \n",
    "app.invoke(state, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82864075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
